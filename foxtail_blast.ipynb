{
 "metadata": {
  "name": "",
  "signature": "sha256:53f813b49198921c4b38e2d60f419d8f6e8f54ab28545fcfd52a4468f7938218"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Foxtail Blasting\n",
      "\n",
      "This will create a file of contigs that have SNPs in them, so only the relevant contigs will be blasted against the 1.01 version of the loblolly genome.  The actual blasting will occur on an iPlant atmosphere instance."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from Bio import SeqIO\n",
      "import os\n",
      "from Bio.Blast import NCBIXML\n",
      "import matplotlib.pyplot as plt\n",
      "from BCBio import GFF\n",
      "from pprint import pprint\n",
      "import dill\n",
      "from IPython.display import FileLink\n",
      "import xml.etree.ElementTree as ET\n",
      "import stopwatch"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "snp_file = \"/home/cfriedline/final_maps_cleaned.txt.cf.txt\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "snp_data = pd.read_csv(snp_file, sep=\"\\t\", index_col=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "contigs = set(snp_data.index)\n",
      "len(contigs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "20655"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assembly = \"/home/cfriedline/data7/assemblies/foxtail2/Green_26_ATCGCGCAA.fastq_31_data_31/contigs.fa\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count = 0\n",
      "out = open(os.path.join(os.path.dirname(assembly), \"contigs_with_snps.fa\"), \"w\")\n",
      "reads = []\n",
      "for read in SeqIO.parse(assembly, \"fasta\"):\n",
      "    if read.id in contigs:\n",
      "        reads.append(read)\n",
      "        count += 1\n",
      "SeqIO.write(reads, out, \"fasta\")\n",
      "out.close()\n",
      "print out.name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "/home/cfriedline/data7/assemblies/foxtail2/Green_26_ATCGCGCAA.fastq_31_data_31/contigs_with_snps.fa"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!grep -c \">\" {out.name}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "20655 "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blast_file = os.path.join(os.path.dirname(assembly), \"contigs_with_snps.fa_blast.xml\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timer = stopwatch.Timer()\n",
      "query_percs = []\n",
      "id_percs = []\n",
      "good_hits  = 0\n",
      "good_queries = 0\n",
      "query_min = 50\n",
      "id_min = 75\n",
      "total_recs = 0\n",
      "query_lens = []\n",
      "good_hit_info = {'len':[], 'len_perc':[], 'id_perc':[]}\n",
      "for i, record in enumerate(NCBIXML.parse(open(blast_file))):\n",
      "    if len(record.alignments) > 0:\n",
      "        snp_data.loc[record.query,\"hits\"] = \"\"\n",
      "        hit_defs = set()\n",
      "        for aln in record.alignments:\n",
      "            for hsp in aln.hsps:\n",
      "                query_perc = ((hsp.query_end - hsp.query_start)+1)*100.0/record.query_length\n",
      "                query_percs.append(query_perc)\n",
      "                query_lens.append(record.query_length)\n",
      "                id_perc = hsp.identities*100.0/hsp.align_length\n",
      "                id_percs.append(id_perc)\n",
      "                if query_perc >= query_min and id_perc >= id_min:\n",
      "                    hit_defs.add(\"%s:%d:%d\" % (aln.hit_def, hsp.sbjct_start, hsp.sbjct_end))\n",
      "                    good_hits += 1\n",
      "                    good_hit_info['len'].append(record.query_length)\n",
      "                    good_hit_info['len_perc'].append(query_perc)\n",
      "                    good_hit_info['id_perc'].append(id_perc)\n",
      "        if len(hit_defs) > 0:\n",
      "            good_queries += 1\n",
      "            snp_data.loc[record.query,\"hits\"] = \"|\".join(hit_defs)\n",
      "    total_recs += 1\n",
      "#     if i == 100:\n",
      "#         break\n",
      "\n",
      "#make sure blank columns are nan\n",
      "snp_data.hits = snp_data.hits.replace(\"\", np.nan)\n",
      "\n",
      "timer.stop()\n",
      "print \"found %d good hits (%d queries) out of %d records (%.2f%%) in %s \" % (good_hits, \n",
      "                                                                             good_queries,\n",
      "                                                                             total_recs, \n",
      "                                                                             good_queries*100.0/total_recs, \n",
      "                                                                             timer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "found 5853 good hits out of 20655 records (28.34%) in 62.5211009979 sec "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = plt.gcf()\n",
      "f.set_size_inches(15, 5)\n",
      "plt.subplot(1,3,1)\n",
      "plt.hist(query_lens)\n",
      "plt.title(\"query lens (%.2f, [%d,%d])\" % (np.mean(query_lens), np.min(query_lens), np.max(query_lens)))\n",
      "plt.subplot(1,3,2)\n",
      "plt.hist(query_percs)\n",
      "plt.title(\"query percent (%.2f, [%d,%d])\" % (np.mean(query_percs), np.min(query_percs), np.max(query_percs)))\n",
      "plt.xlabel(\"n = %d\" % len(query_percs))\n",
      "plt.subplot(1,3,3)\n",
      "plt.hist(id_percs)\n",
      "plt.title(\"identity percent (%.2f, [%d,%d])\" % (np.mean(id_percs), np.min(id_percs), np.max(id_percs)))\n",
      "plt.xlabel(\"n = %d\" % len(id_percs))\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "query_lens = good_hit_info['len']\n",
      "query_percs = good_hit_info['len_perc']\n",
      "id_percs = good_hit_info['id_perc']\n",
      "f = plt.gcf()\n",
      "f.set_size_inches(15, 5)\n",
      "plt.subplot(1,3,1)\n",
      "plt.hist(query_lens)\n",
      "plt.title(\"query lens (%.2f +/- %.2f [%d,%d])\" % (np.mean(query_lens), np.std(query_lens), np.min(query_lens), np.max(query_lens)))\n",
      "plt.subplot(1,3,2)\n",
      "plt.hist(query_percs)\n",
      "plt.title(\"query percent (%.2f +/- %.2f [%d,%d])\" % (np.mean(query_percs), np.std(query_percs), np.min(query_percs), np.max(query_percs)))\n",
      "plt.xlabel(\"n = %d\" % len(query_percs))\n",
      "plt.subplot(1,3,3)\n",
      "plt.hist(id_percs)\n",
      "plt.title(\"identity percent (%.2f +/- %.2f [%d,%d])\" % (np.mean(id_percs), np.std(id_percs), np.min(id_percs), np.max(id_percs)))\n",
      "plt.xlabel(\"n = %d\" % len(id_percs))\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Example output of contigs with SNPs that have blast hits to loblolly genome\n",
      "\n",
      "    Contig\n",
      "    NODE_238065_length_62_cov_2.032258                            NaN\n",
      "    NODE_238076_length_63_cov_2.000000     scaffold182951:49338:49426\n",
      "    NODE_238141_length_74_cov_1.405405                            NaN\n",
      "    NODE_23738_length_63_cov_3.365079                             NaN\n",
      "    NODE_238177_length_63_cov_2.873016    tscaffold4746:529693:529745\n",
      "    NODE_238212_length_63_cov_3.126984                            NaN\n",
      "    NODE_23741_length_63_cov_2.000000                             NaN\n",
      "    NODE_238275_length_63_cov_2.952381                            NaN\n",
      "    NODE_238282_length_63_cov_3.952381                            NaN\n",
      "    NODE_238286_length_63_cov_2.396825                            NaN\n",
      "    NODE_238334_length_93_cov_1.193548                            NaN\n",
      "    NODE_238336_length_63_cov_3.000000    tscaffold7265:307711:307803\n",
      "    NODE_238369_length_63_cov_2.000000                            NaN\n",
      "    NODE_238392_length_63_cov_3.873016                            NaN\n",
      "    NODE_238427_length_63_cov_2.000000                            NaN\n",
      "    ...\n",
      "    NODE_237783_length_102_cov_2.519608                            NaN\n",
      "    NODE_237799_length_63_cov_2.730159                             NaN\n",
      "    NODE_237834_length_63_cov_3.000000                             NaN\n",
      "    NODE_237860_length_63_cov_1.111111                             NaN\n",
      "    NODE_237919_length_63_cov_3.000000                             NaN\n",
      "    NODE_237920_length_63_cov_2.000000                             NaN\n",
      "    NODE_237925_length_71_cov_1.422535                             NaN\n",
      "    NODE_237929_length_62_cov_2.000000                             NaN\n",
      "    NODE_237930_length_62_cov_4.516129     tscaffold3881:650763:650672\n",
      "    NODE_237931_length_63_cov_3.000000                             NaN\n",
      "    NODE_237940_length_64_cov_1.609375                             NaN\n",
      "    NODE_237998_length_63_cov_2.968254                             NaN\n",
      "    NODE_238044_length_63_cov_2.000000                             NaN\n",
      "    NODE_238054_length_63_cov_2.539683                             NaN\n",
      "    NODE_238058_length_63_cov_2.000000                             NaN\n",
      "    Name: hits, Length: 20655, dtype: object"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gff_dir = \"/home/cfriedline\"\n",
      "gff_files = ['ptaeda.v1.01.scaffolds.trimmed.all.genes.highq_partial.gff',\n",
      "             'ptaeda.v1.01.scaffolds.trimmed.all.genes.highq_whole.gff',\n",
      "             'ptaeda.v1.01.scaffolds.trimmed.all.genes.lowq_whole.gff',\n",
      "             'ptaeda.v1.01.scaffolds.trimmed.all.genes.lowq_partial.gff']\n",
      "gff_files = [os.path.join(gff_dir, x) for x in gff_files]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this cell crushes the kernel\n",
      "timer = stopwatch.Timer()\n",
      "gff_data = {}\n",
      "for gff in gff_files:\n",
      "    print gff\n",
      "    inner = {}\n",
      "    inner['data'] = list(GFF.parse(gff))\n",
      "    gff_data[os.path.basename(gff)] = inner\n",
      "timer.stop()\n",
      "print timer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for key, v in gff_data.items():\n",
      "    data = v['data']\n",
      "    index = {}\n",
      "    v['index'] = index\n",
      "    print key, len(data)\n",
      "    for elem in data:\n",
      "        index[elem.id] = elem"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def split_hit(series):\n",
      "    try:\n",
      "        float(series.hits)\n",
      "        return series.hits\n",
      "    except:\n",
      "        return [x.split(\":\") for x in str(series.hits).split(\"|\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hits = snp_data.apply(split_hit, axis=1).dropna()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count = 0\n",
      "for hit in hits:\n",
      "    index = hits.index[count]\n",
      "    hit_anno = []\n",
      "    for triplet in hit:\n",
      "        hit_coords = sorted([int(triplet[1]), int(triplet[2])])\n",
      "        for key, data in gff_data.items():\n",
      "            if triplet[0] in data['index']:\n",
      "                rec = data['index'][triplet[0]]\n",
      "                for f in rec.features:\n",
      "                    genome_coords = sorted([f.location.nofuzzy_start, f.location.nofuzzy_end])\n",
      "                    if (hit_coords[0] >= genome_coords[0]) and (hit_coords[1] <= genome_coords[1]):\n",
      "                        hit_anno.append(str(f.qualifiers))\n",
      "    snp_data.loc[index, 'annotation'] = str(hit_anno)\n",
      "    count+=1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in snp_data.annotation.to_dict().items():\n",
      "    try:\n",
      "        float(v)\n",
      "    except:\n",
      "        data = eval(v)\n",
      "        if len(data) > 0:\n",
      "            for elem in data:\n",
      "                d = eval(elem)\n",
      "                if 'Ontology_term' in d:\n",
      "                    snp_data.loc[k, 'ontology_term'] = str(d['Ontology_term'])\n",
      "                if 'Dbxref' in d:\n",
      "                    snp_data.loc[k, 'dbxref'] = str(d['Dbxref'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def is_null(val):\n",
      "    try:\n",
      "        float(val)\n",
      "        return True\n",
      "    except:\n",
      "        return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "snp_data.ontology_term"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean_row(series):\n",
      "    if is_null(series.dbxref):\n",
      "        series.dbxref=\"\"\n",
      "    else:\n",
      "        series.dbxref = '|'.join(eval(series.dbxref))\n",
      "        \n",
      "    if is_null(series.ontology_term):\n",
      "        series.ontology_term = \"\"\n",
      "    else:\n",
      "        series.ontology_term = '|'.join(eval(series.ontology_term))\n",
      "    return series"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_data():\n",
      "    f = os.path.basename(snp_file+\"_mod.txt\")\n",
      "    c = snp_data.drop('annotation', axis=1)\n",
      "    c = snp_data.apply(clean_row, axis=1)\n",
      "    c.to_csv(f, sep=\"\\t\")\n",
      "    return FileLink(f)\n",
      "write_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Start here if you're skipping gff data\n",
      "\n",
      "Presumably b/c you've already run and imported it from above.  Hack to get around the kernel getting bogged down when the gff data is loaded"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "go_terms = snp_data.ontology_term.dropna().apply(lambda x: eval(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "go_set = set()\n",
      "go_list = []\n",
      "for val in go_terms:\n",
      "    for elem in val:\n",
      "        go_set.add(elem)\n",
      "        go_list.append(elem)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import MySQLdb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "See http://wiki.geneontology.org/index.php/Example_Queries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn = MySQLdb.connect(host='mysql.ebi.ac.uk', \n",
      "                       user='go_select', \n",
      "                       passwd='amigo', \n",
      "                       db='go_latest', \n",
      "                       port=4085)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "go_results = {}\n",
      "for i, term_id in enumerate(sorted(go_list)):\n",
      "    print \"%d/%d\" % (i, len(go_list))\n",
      "    cur = conn.cursor()\n",
      "    cur.execute(\"SELECT * FROM term WHERE acc='%s'\" % term_id)\n",
      "    for row in cur.fetchall():\n",
      "#         print \"row %s\" % str(row)\n",
      "        ont = row[2]\n",
      "        term = row[1]\n",
      "        if not ont in go_results:\n",
      "            go_results[ont] = {}\n",
      "        else:\n",
      "            if not term in go_results[ont]:\n",
      "                go_results[ont][term] = 1\n",
      "            else:\n",
      "                go_results[ont][term] += 1\n",
      "    cur.close()\n",
      "conn.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "go_out = \"go_res.txt\"\n",
      "with open(go_out, \"w\") as o:\n",
      "    o.write(\"ont\\tterm\\tcount\\n\")\n",
      "    for ont, v in go_results.items():\n",
      "        for term, count in v.items():\n",
      "            o.write(\"%s\\t%s\\t%d\\n\" % (ont, term, count))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FileLink(go_out)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interpro = 0\n",
      "for x in snp_data.dbxref.dropna().apply(lambda x: [x for x in set(eval(x)) if 'InterPro' in x]):\n",
      "    interpro += len(x)\n",
      "print interpro"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Work with InterPro"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@dview.remote(block=True)\n",
      "def read_interpro_xml():\n",
      "    from lxml import etree\n",
      "    global interpro\n",
      "    interpro = etree.parse(\"/home/cfriedline/interpro/interpro.xml\")\n",
      "res = read_interpro_xml()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "root = interpro.getroot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "anno = snp_data.annotation.dropna().apply(lambda x: eval(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc = Client(profile=\"default\")\n",
      "dview = rc[:]\n",
      "lview = rc.load_balanced_view()\n",
      "dview['interpro'] = etree.parse(\"/home/cfriedline/interpro/interpro.xml\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@lview.remote()\n",
      "def find_interpro_data(index, interpro_id):\n",
      "    node = interpro.getroot().find(\".//interpro[@id='%s']\" % interpro_id)\n",
      "    if node is not None:\n",
      "        name = node.find('name').text\n",
      "        return index, name\n",
      "    return index, None\n",
      "#         classification = node.findall('class_list/classification')\n",
      "#         for c in classification:\n",
      "#             class_type = c.get('class_type')\n",
      "#             if class_type==\"GO\":\n",
      "#                 return name, c.get('id'), class_type, c.find('category').text, c.find('description').text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ip_key = \"Dbxref\"\n",
      "interpro_tasks = []\n",
      "for i, x in enumerate(anno):\n",
      "    #print \"%d/%d\" % (i, len(anno))\n",
      "    interpro_annos = set()\n",
      "    if len(x) > 0:\n",
      "        for elem in x:\n",
      "            elem = eval(elem)\n",
      "            if ip_key in elem:\n",
      "                ip_ids = [x.split(\":\")[1] for x in set(elem[ip_key]) if 'InterPro' in x]\n",
      "                for ip_id in ip_ids:\n",
      "                    interpro_tasks.append(find_interpro_data(anno.index[i], ip_id))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interpro_dict = {}\n",
      "for i, task in enumerate(interpro_tasks):\n",
      "    res = task.r\n",
      "    if not res[0] in interpro_dict:\n",
      "        interpro_dict[res[0]] = []\n",
      "    if res[1]:\n",
      "        interpro_dict[res[0]].append(res[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in interpro_dict.items():\n",
      "    if len(v) > 0:\n",
      "        snp_data.loc[k, 'interpro'] = '|'.join(v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    }
   ],
   "metadata": {}
  }
 ]
}